{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "246ff23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rd\n",
    "from sklearn.preprocessing import StandardScaler as ss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6f1a9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig(x):\n",
    "    x_64=x.astype(float)\n",
    "    return 1/(1+np.exp(-x_64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "649d0ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataset from titanic dataset\n",
    "data=pd.read_csv(\"train.csv\")[[\"Survived\",\"Pclass\",\"Sex\",\"Age\",\"Fare\",\"SibSp\",\"Parch\"]]\n",
    "data=data.fillna(value={\"Age\":np.mean(data[\"Age\"])})\n",
    "data.loc[data.Sex==\"male\",\"Sex\"]=0\n",
    "data.loc[data.Sex==\"female\",\"Sex\"]=1\n",
    "\n",
    "X_train=data[[\"Pclass\",\"Sex\",\"Age\",\"Fare\",\"SibSp\",\"Parch\"]]\n",
    "Y_train=data[[\"Survived\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a5ae408",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83e45256",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13b82828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass Sex        Age     Fare  SibSp  Parch\n",
       "0         0       3   0  22.000000   7.2500      1      0\n",
       "1         1       1   1  38.000000  71.2833      1      0\n",
       "2         1       3   1  26.000000   7.9250      0      0\n",
       "3         1       1   1  35.000000  53.1000      1      0\n",
       "4         0       3   0  35.000000   8.0500      0      0\n",
       "5         0       3   0  29.699118   8.4583      0      0\n",
       "6         0       1   0  54.000000  51.8625      0      0\n",
       "7         0       3   0   2.000000  21.0750      3      1\n",
       "8         1       3   1  27.000000  11.1333      0      2\n",
       "9         1       2   1  14.000000  30.0708      1      0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7aa77cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize our data\n",
    "s=ss()\n",
    "X_train=s.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c329256",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X=np.array(X_train)\n",
    "Y=Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e2cd5b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X,Y,*arch,lr=1,b=0.9):\n",
    "    weights=[]\n",
    "    start_cap_deltas=[]\n",
    "    for i in range(len(arch)-1):\n",
    "        weights.append(np.array([[rd.uniform(-0.5,0.5) for k in range(arch[i])] for j in range(arch[i+1])]))\n",
    "        start_cap_deltas.append(np.array([[0 for k in range(arch[i])] for j in range(arch[i+1])]))\n",
    "        #creating weight matrices and weights updates accumulators according to ANN architecture\n",
    "    k=0\n",
    "    delta_cost=1\n",
    "    cost_values=[] \n",
    "    cap_deltas=[]  \n",
    "    while(delta_cost>=0.0000001): \n",
    "        cap_deltas.clear()\n",
    "        for i in range(len(arch)-1):\n",
    "            cap_deltas.append(np.array([[0 for k in range(arch[i])] for j in range(arch[i+1])]))\n",
    "        k+=1\n",
    "        sum_er=0\n",
    "\n",
    "        if k>2:\n",
    "            del cost_values[0]\n",
    "        for t in range(len(X)):\n",
    "            #forward propagation\n",
    "            a=[]\n",
    "            z=[]\n",
    "            for i in range(len(arch)):\n",
    "                if i==0:\n",
    "                    a.append(X[t].reshape(1,arch[0]))\n",
    "                else:\n",
    "                    z.append(np.matmul(a[i-1],weights[i-1].transpose()))\n",
    "                    a.append(sig(z[i-1]))\n",
    "\n",
    "            #backpropagation\n",
    "            E_total=-Y[t]*np.log(a[len(arch)-1])-(1-Y[t])*np.log(1-a[len(arch)-1])\n",
    "            sum_er+=E_total\n",
    "            deltas=[]\n",
    "\n",
    "            for i in range(len(arch)-1,0,-1): #calculating delta terms for each layer\n",
    "                if i==len(arch)-1:\n",
    "                    deltas.append(a[i]-Y[t])\n",
    "                else:\n",
    "                    deltas=[np.array(np.matmul(deltas[0],weights[i])*a[i]*(1-a[i]))]+deltas\n",
    "            #deltas[0] corresponds to second delta term dletas[1] corresponds to third delta term etc, if numerating \n",
    "            #of layers started from 1\n",
    "\n",
    "            d_weights=[]\n",
    "            for i in range(len(weights)):#calculating d_weight for each weight\n",
    "                d_weights.append(np.matmul(deltas[i].transpose(),a[i]))\n",
    "                cap_deltas[i]=cap_deltas[i]+d_weights[i] #accumulate weights updates\n",
    "        print()\n",
    "        for i in range(len(weights)):#change weights according to acuumulated values\n",
    "            weights[i]=weights[i]-lr/len(X)*cap_deltas[i]\n",
    "        cost=1/len(X)*sum_er\n",
    "        cost_values.append(*cost)\n",
    "        if k>=2:\n",
    "            delta_cost=cost_values[0]-cost_values[1]\n",
    "\n",
    "        print(\"it number {0}, cost is {1}\".format(k,cost))\n",
    "    else:\n",
    "        lr=lr*0.9\n",
    "        print(\"we stopped cause cost function didn't change, lr ={0}\".format(lr))\n",
    "        print(\"delta_cost=%f\" % delta_cost)\n",
    "    \"\"\"\n",
    "    массив a=выходы с нейронов, нулевой элемент- вектор выходов с первого слоя\n",
    "    массив z=входы с нейронов, нулевой эл-т- вектор входов во второй нейрон\n",
    "    массив weights=матрицы весов, нулевой эл-т- матрица весов с первого слоя на второй\n",
    "    массив deltas=массив ошибок на входе каждого из слоев, кроме первого. Нулевой элемент-ошибка на входе нейронов второго слоя\n",
    "    массив d_weights=массив необходимых изменений матриц весов после запуска нейронной сети для одного объекта. Нулевой эл-т-\n",
    "    необходимое изменение матрицы весов с первого слоя на второй\n",
    "    массив cap_deltas=массив необходимых изменений матриц весов после одного пробега по всем объектам матрицы входных значений.\n",
    "    Нулевой эл-т-суммарное изменение матрицы весов с первого слоя на второй\n",
    "\n",
    "    \"\"\"   \n",
    "    print(weights)\n",
    "    return weights,arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ab801fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "it number 1, cost is [[0.64925997]]\n",
      "\n",
      "it number 2, cost is [[0.63846068]]\n",
      "\n",
      "it number 3, cost is [[0.62036582]]\n",
      "\n",
      "it number 4, cost is [[0.62812975]]\n",
      "we stopped cause cost function didn't change, lr =0.9\n",
      "delta_cost=-0.007764\n",
      "[array([[ 0.01561422,  0.31451536,  0.2182664 , -0.37797928, -0.44909274,\n",
      "        -0.35782986],\n",
      "       [ 0.19330271, -0.45193916,  0.07742919,  0.38264628, -0.27875769,\n",
      "        -0.46270422],\n",
      "       [-0.04369952,  0.53102153, -0.11090952, -0.15242786,  0.04696118,\n",
      "        -0.49104771],\n",
      "       [-0.4390238 , -0.28782839, -0.18953005, -0.35616583,  0.01807733,\n",
      "         0.43881862],\n",
      "       [-0.52828981,  0.4433716 , -0.45901018, -0.18819791, -0.26960586,\n",
      "        -0.08555359],\n",
      "       [-0.1543763 , -0.09474819, -0.15835374, -0.38934237, -0.02600365,\n",
      "        -0.008548  ],\n",
      "       [-0.4035926 ,  0.45228024, -0.33396346, -0.00478474,  0.38857255,\n",
      "         0.07265997],\n",
      "       [ 0.30343408,  0.48507746, -0.07437564, -0.43647659,  0.2660212 ,\n",
      "        -0.04104129],\n",
      "       [-0.51874045,  0.3324516 ,  0.3215427 ,  0.07771516, -0.25861575,\n",
      "         0.41756906],\n",
      "       [ 0.34893688, -0.08256143, -0.41416622,  0.34504319,  0.34448949,\n",
      "         0.20901033],\n",
      "       [-0.3753586 , -0.31415915,  0.48688286, -0.39868741,  0.00977753,\n",
      "        -0.01625578],\n",
      "       [-0.09023882, -0.21759001, -0.25200173, -0.22796674, -0.01186942,\n",
      "         0.25617038],\n",
      "       [-0.0327243 ,  0.00438928,  0.06480378,  0.2373218 , -0.46205424,\n",
      "         0.19137126],\n",
      "       [ 0.18954108,  0.0883802 ,  0.48918974,  0.34127492,  0.10011473,\n",
      "         0.07644698],\n",
      "       [-0.02540082, -0.2320167 , -0.08128552, -0.02096269,  0.4719985 ,\n",
      "        -0.25208306],\n",
      "       [ 0.2863896 , -0.4192632 , -0.07459342, -0.21188741,  0.1156781 ,\n",
      "         0.02110833],\n",
      "       [-0.08924787, -0.50601556,  0.36077337, -0.44478803, -0.34598798,\n",
      "        -0.32333718],\n",
      "       [ 0.19305623, -0.24869715, -0.18322689, -0.39037281,  0.24547686,\n",
      "         0.4169855 ],\n",
      "       [ 0.03557918, -0.01721756,  0.31777904,  0.118636  , -0.40438978,\n",
      "         0.2082153 ],\n",
      "       [-0.25867363,  0.17775904,  0.49078269,  0.36298096, -0.17171982,\n",
      "         0.11073596],\n",
      "       [ 0.00876677,  0.33096352,  0.04874258,  0.2267814 ,  0.13179615,\n",
      "         0.1105919 ],\n",
      "       [ 0.01373691,  0.25333423,  0.17546307, -0.42276932,  0.3393796 ,\n",
      "         0.11817656],\n",
      "       [ 0.44932309, -0.39490244,  0.30123878,  0.15193709,  0.38989238,\n",
      "        -0.40085378],\n",
      "       [ 0.04489297, -0.03395155,  0.45756677,  0.2284834 ,  0.0923553 ,\n",
      "        -0.43011125],\n",
      "       [-0.02550806, -0.29873218,  0.0782315 , -0.14743607,  0.16766912,\n",
      "         0.00119639],\n",
      "       [-0.43349039,  0.06925287, -0.01997629, -0.42701045,  0.24485279,\n",
      "         0.09105395],\n",
      "       [-0.17575283,  0.02981064, -0.19491804,  0.17217413,  0.02132789,\n",
      "         0.43111108],\n",
      "       [-0.17482438, -0.11383207, -0.45650472, -0.42770821,  0.13603369,\n",
      "         0.15170025],\n",
      "       [-0.10965405, -0.49317839,  0.2132658 ,  0.32074781,  0.03768011,\n",
      "         0.13926855],\n",
      "       [-0.00893113,  0.04739579,  0.14633906, -0.31577243, -0.28381306,\n",
      "         0.30631766],\n",
      "       [ 0.32194962, -0.40560745, -0.07708469,  0.41478272,  0.42652053,\n",
      "        -0.09005008],\n",
      "       [ 0.40387552, -0.47833027,  0.47826343, -0.37124565, -0.36966317,\n",
      "         0.10703858],\n",
      "       [-0.2559068 , -0.44270767, -0.00398521, -0.04925353, -0.31314327,\n",
      "        -0.15160055],\n",
      "       [-0.00807151, -0.3105656 , -0.47149638, -0.32613394,  0.05961066,\n",
      "        -0.17648655],\n",
      "       [ 0.02361693,  0.26111065,  0.05112497, -0.38757192,  0.38216208,\n",
      "        -0.21995545],\n",
      "       [-0.06210776, -0.22478823,  0.37332668, -0.17337849, -0.24201348,\n",
      "        -0.05888712],\n",
      "       [-0.13360418,  0.02874565,  0.2509666 ,  0.04761046,  0.14483647,\n",
      "        -0.27429983],\n",
      "       [ 0.40918674,  0.52990555, -0.31958534,  0.46921226,  0.30864414,\n",
      "         0.25408648],\n",
      "       [ 0.26981649, -0.20857964,  0.06923052, -0.10587955,  0.0118646 ,\n",
      "        -0.09632022],\n",
      "       [ 0.07131605, -0.2812693 ,  0.19376914,  0.46788793,  0.00475017,\n",
      "         0.0483478 ]]), array([[ 0.1036303 , -0.50426788,  0.35478717,  0.21836602,  0.49599342,\n",
      "         0.16756722,  0.41016132,  0.07315979,  0.6197107 , -0.13693658,\n",
      "        -0.48057874, -0.21699833,  0.04983921, -0.32938011,  0.29176023,\n",
      "         0.34384865, -0.36325209, -0.3939997 , -0.23584272,  0.13283371,\n",
      "         0.31571423,  0.08854689, -0.46643296,  0.38355299, -0.39830482,\n",
      "         0.22100402,  0.06103946, -0.33049879, -0.44649724, -0.24926997,\n",
      "         0.3627562 , -0.25187051,  0.20278812,  0.3401918 , -0.0772358 ,\n",
      "        -0.31770953,  0.37557901,  0.38893205, -0.40622989,  0.17327501]])]\n"
     ]
    }
   ],
   "source": [
    "weights,arch=train(X,Y,6,40,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8b7fc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[142]:\n",
    "import random as rd\n",
    "import numpy as np\n",
    "import copy\n",
    "def sig(x):\n",
    "    x_64=x.astype(float)\n",
    "    return 1/(1+np.exp(-x_64))\n",
    "\n",
    "# In[143]:\n",
    "class model:\n",
    "    \n",
    "    \n",
    "    def __init__(s,arch):#create model with specific architecture and random initialized weights and cost_value=1000\n",
    "        \n",
    "        s.arch=arch\n",
    "        s.cost=1000\n",
    "        s.stop=False\n",
    "        s.weights=[\n",
    "            np.array([\n",
    "                [\n",
    "                    rd.uniform(-0.5,0.5) for k in range(arch[i])\n",
    "                ] for j in range(arch[i+1])\n",
    "            ]) for i in range(len(arch)-1)\n",
    "        ]\n",
    "    \n",
    "    \n",
    "    def make_one_iteration(s,X,Y,previous_cost,lr=1,l=0.4):\n",
    "        \n",
    "        s.stop=False\n",
    "        arch=s.arch\n",
    "        weights=copy.deepcopy(s.weights)\n",
    "        cap_deltas=[]\n",
    "        for i in range(len(arch)-1):\n",
    "            cap_deltas.append(np.array([[0 for k in range(arch[i])] for j in range(arch[i+1])]))\n",
    "        sum_er=0\n",
    "        for t in range(len(X)):\n",
    "            #forward propagation\n",
    "            a=[]\n",
    "            z=[]\n",
    "            for i in range(len(arch)):\n",
    "                if i==0:\n",
    "                    a.append(X[t].reshape(1,arch[0]))\n",
    "                else:\n",
    "                    z.append(np.matmul(a[i-1],weights[i-1].transpose()))\n",
    "                    a.append(sig(z[i-1]))\n",
    "\n",
    "            #backpropagation\n",
    "            E_total=-Y[t]*np.log(a[len(arch)-1])-(1-Y[t])*np.log(1- a[len(arch)-1])\n",
    "            sum_er+=E_total\n",
    "            deltas=[]\n",
    "            \n",
    "            for i in range(len(arch)-1,0,-1): #calculating delta terms for each layer\n",
    "                if i==len(arch)-1:\n",
    "                    deltas.append(a[i]-Y[t])\n",
    "                else:\n",
    "                    deltas=[np.array(np.matmul(deltas[0],weights[i])*a[i]*(1-a[i]))]+deltas\n",
    "            #deltas[0] corresponds to second delta term dletas[1] corresponds to third delta term etc, if numerating \n",
    "            #of layers started from 1\n",
    "            \n",
    "            d_weights=[]\n",
    "            for i in range(len(weights)):#calculating d_weight for each weight\n",
    "                d_weights.append(np.matmul(deltas[i].transpose(),a[i]))\n",
    "                cap_deltas[i]=cap_deltas[i]+d_weights[i] #accumulate weights updates\n",
    "\n",
    "        for i in range(len(weights)):#change weights according to acuumulated values\n",
    "            weights[i]=weights[i]-lr/len(X)*cap_deltas[i]\n",
    "        cost=1/len(X)*sum_er.reshape(1,)[0]\n",
    "            \n",
    "        if previous_cost-cost<0.00001:\n",
    "            print(previous_cost-cost)\n",
    "            s.stop=True\n",
    "        s.cost=cost        \n",
    "        s.weights=copy.deepcopy(weights)\n",
    "        \n",
    "        \n",
    "    def train(s,X,Y,lr=1,l=0.4):\n",
    "        k=-1\n",
    "        while s.stop!=True:\n",
    "            k+=1\n",
    "            s.make_one_iteration(X,Y,s.cost,lr,l)\n",
    "            print(\"iteration number {0}, cost is {1}\".format(k,s.cost))\n",
    "        print(\"We stopped cause cost function didn't change enough in last iteration\")  \n",
    "\n",
    "    def predict(s,X):\n",
    "        predictions=[]\n",
    "        weights=s.weights\n",
    "        for t in range(len(X)):\n",
    "        #forward propagation\n",
    "            a=[]\n",
    "            z=[]\n",
    "            for i in range(len(s.arch)):\n",
    "                if i==0:\n",
    "                    a.append(X[t].reshape(1,s.arch[0]))\n",
    "                else:\n",
    "                    z.append(np.matmul(a[i-1],weights[i-1].transpose()))\n",
    "                    a.append(sig(z[i-1]))\n",
    "            predictions.append(a[len(s.arch)-1])\n",
    "        return np.array(predictions).reshape(len(predictions,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ab53e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn=model([6,20,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2021ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number 0, cost is 0.760241947532461\n",
      "iteration number 1, cost is 0.680610374198359\n",
      "iteration number 2, cost is 0.6580515620307652\n",
      "iteration number 3, cost is 0.6387646992317775\n",
      "iteration number 4, cost is 0.6217652342242134\n",
      "iteration number 5, cost is 0.6065796057380446\n",
      "iteration number 6, cost is 0.5928908089009651\n",
      "iteration number 7, cost is 0.5804772302838289\n",
      "iteration number 8, cost is 0.5691794477395352\n",
      "iteration number 9, cost is 0.5588778986202717\n",
      "iteration number 10, cost is 0.5494780296969124\n",
      "iteration number 11, cost is 0.5409007245424541\n",
      "iteration number 12, cost is 0.5330764292751801\n",
      "iteration number 13, cost is 0.5259417869070122\n",
      "iteration number 14, cost is 0.5194378921445822\n",
      "iteration number 15, cost is 0.513509522389607\n",
      "iteration number 16, cost is 0.5081048993717197\n",
      "iteration number 17, cost is 0.5031756920145387\n",
      "iteration number 18, cost is 0.498677087397616\n",
      "iteration number 19, cost is 0.4945678378292224\n",
      "iteration number 20, cost is 0.490810244696558\n",
      "iteration number 21, cost is 0.4873700710435361\n",
      "iteration number 22, cost is 0.48421639127543187\n",
      "iteration number 23, cost is 0.48132139331652635\n",
      "iteration number 24, cost is 0.4786601498802458\n",
      "iteration number 25, cost is 0.47621037392849597\n",
      "iteration number 26, cost is 0.47395217058408606\n",
      "iteration number 27, cost is 0.4718677946914497\n",
      "iteration number 28, cost is 0.4699414203991293\n",
      "iteration number 29, cost is 0.46815892677534665\n",
      "iteration number 30, cost is 0.46650770161475824\n",
      "iteration number 31, cost is 0.46497646421578637\n",
      "iteration number 32, cost is 0.46355510693396745\n",
      "iteration number 33, cost is 0.4622345546687923\n",
      "iteration number 34, cost is 0.461006641044676\n",
      "iteration number 35, cost is 0.45986399983614507\n",
      "iteration number 36, cost is 0.45879997010947987\n",
      "iteration number 37, cost is 0.4578085135657668\n",
      "iteration number 38, cost is 0.45688414264098526\n",
      "iteration number 39, cost is 0.4560218580236987\n",
      "iteration number 40, cost is 0.4552170943728524\n",
      "iteration number 41, cost is 0.45446567314554404\n",
      "iteration number 42, cost is 0.45376376156969245\n",
      "iteration number 43, cost is 0.45310783691474016\n",
      "iteration number 44, cost is 0.4524946553222912\n",
      "iteration number 45, cost is 0.4519212245568378\n",
      "iteration number 46, cost is 0.45138478012428024\n",
      "iteration number 47, cost is 0.45088276428316826\n",
      "iteration number 48, cost is 0.45041280754115526\n",
      "iteration number 49, cost is 0.44997271228798746\n",
      "iteration number 50, cost is 0.44956043826719017\n",
      "iteration number 51, cost is 0.4491740896325247\n",
      "iteration number 52, cost is 0.4488119033729576\n",
      "iteration number 53, cost is 0.44847223892216526\n",
      "iteration number 54, cost is 0.4481535687961226\n",
      "iteration number 55, cost is 0.4478544701258266\n",
      "iteration number 56, cost is 0.44757361697211406\n",
      "iteration number 57, cost is 0.44730977332643856\n",
      "iteration number 58, cost is 0.44706178671577174\n",
      "iteration number 59, cost is 0.44682858234185174\n",
      "iteration number 60, cost is 0.4466091576952023\n",
      "iteration number 61, cost is 0.4464025775928812\n",
      "iteration number 62, cost is 0.4462079695961752\n",
      "iteration number 63, cost is 0.4460245197704751\n",
      "iteration number 64, cost is 0.4458514687546776\n",
      "iteration number 65, cost is 0.4456881081117668\n",
      "iteration number 66, cost is 0.44553377693579205\n",
      "iteration number 67, cost is 0.4453878586935212\n",
      "iteration number 68, cost is 0.4452497782816147\n",
      "iteration number 69, cost is 0.4451189992823173\n",
      "iteration number 70, cost is 0.4449950214025221\n",
      "iteration number 71, cost is 0.44487737808260275\n",
      "iteration number 72, cost is 0.44476563426279153\n",
      "iteration number 73, cost is 0.4446593842959876\n",
      "iteration number 74, cost is 0.44455824999690474\n",
      "iteration number 75, cost is 0.4444618788183362\n",
      "iteration number 76, cost is 0.44436994214604203\n",
      "iteration number 77, cost is 0.4442821337044676\n",
      "iteration number 78, cost is 0.44419816806606366\n",
      "iteration number 79, cost is 0.44411777925753537\n",
      "iteration number 80, cost is 0.44404071945677553\n",
      "iteration number 81, cost is 0.4439667577747297\n",
      "iteration number 82, cost is 0.44389567911675193\n",
      "iteration number 83, cost is 0.44382728311844516\n",
      "iteration number 84, cost is 0.44376138315123426\n",
      "iteration number 85, cost is 0.44369780539327336\n",
      "iteration number 86, cost is 0.4436363879615283\n",
      "iteration number 87, cost is 0.4435769801011716\n",
      "iteration number 88, cost is 0.44351944142862254\n",
      "iteration number 89, cost is 0.4434636412248281\n",
      "iteration number 90, cost is 0.4434094577755803\n",
      "iteration number 91, cost is 0.4433567777558283\n",
      "iteration number 92, cost is 0.44330549565520083\n",
      "iteration number 93, cost is 0.44325551324204404\n",
      "iteration number 94, cost is 0.4432067390635042\n",
      "iteration number 95, cost is 0.4431590879793122\n",
      "iteration number 96, cost is 0.44311248072707393\n",
      "iteration number 97, cost is 0.4430668435170054\n",
      "iteration number 98, cost is 0.44302210765418853\n",
      "iteration number 99, cost is 0.44297820918653497\n",
      "iteration number 100, cost is 0.4429350885767508\n",
      "iteration number 101, cost is 0.4428926903967326\n",
      "iteration number 102, cost is 0.44285096304288235\n",
      "iteration number 103, cost is 0.44280985847096277\n",
      "iteration number 104, cost is 0.4427693319491788\n",
      "iteration number 105, cost is 0.44272934182826124\n",
      "iteration number 106, cost is 0.44268984932741684\n",
      "iteration number 107, cost is 0.44265081833506553\n",
      "iteration number 108, cost is 0.4426122152233679\n",
      "iteration number 109, cost is 0.44257400867560687\n",
      "iteration number 110, cost is 0.44253616952555064\n",
      "iteration number 111, cost is 0.44249867060798165\n",
      "iteration number 112, cost is 0.442461486619621\n",
      "iteration number 113, cost is 0.44242459398973955\n",
      "iteration number 114, cost is 0.44238797075980224\n",
      "iteration number 115, cost is 0.44235159647149896\n",
      "iteration number 116, cost is 0.4423154520626109\n",
      "iteration number 117, cost is 0.442279519770157\n",
      "iteration number 118, cost is 0.4422437830403125\n",
      "iteration number 119, cost is 0.44220822644464153\n",
      "iteration number 120, cost is 0.44217283560220355\n",
      "iteration number 121, cost is 0.44213759710711537\n",
      "iteration number 122, cost is 0.44210249846119737\n",
      "iteration number 123, cost is 0.44206752801135607\n",
      "iteration number 124, cost is 0.4420326748913534\n",
      "iteration number 125, cost is 0.44199792896766604\n",
      "iteration number 126, cost is 0.4419632807891677\n",
      "iteration number 127, cost is 0.44192872154032375\n",
      "iteration number 128, cost is 0.44189424299769325\n",
      "iteration number 129, cost is 0.4418598374894846\n",
      "iteration number 130, cost is 0.44182549785795106\n",
      "iteration number 131, cost is 0.44179121742444627\n",
      "iteration number 132, cost is 0.44175698995691376\n",
      "iteration number 133, cost is 0.4417228096396858\n",
      "iteration number 134, cost is 0.4416886710453906\n",
      "iteration number 135, cost is 0.4416545691088432\n",
      "iteration number 136, cost is 0.441620499102769\n",
      "iteration number 137, cost is 0.44158645661522994\n",
      "iteration number 138, cost is 0.44155243752864853\n",
      "iteration number 139, cost is 0.44151843800029117\n",
      "iteration number 140, cost is 0.44148445444413065\n",
      "iteration number 141, cost is 0.4414504835139828\n",
      "iteration number 142, cost is 0.44141652208782145\n",
      "iteration number 143, cost is 0.4413825672531958\n",
      "iteration number 144, cost is 0.44134861629367367\n",
      "iteration number 145, cost is 0.4413146666762296\n",
      "iteration number 146, cost is 0.4412807160395157\n",
      "iteration number 147, cost is 0.4412467621829593\n",
      "iteration number 148, cost is 0.44121280305662164\n",
      "iteration number 149, cost is 0.4411788367517573\n",
      "iteration number 150, cost is 0.44114486149204646\n",
      "iteration number 151, cost is 0.4411108756254225\n",
      "iteration number 152, cost is 0.44107687761648795\n",
      "iteration number 153, cost is 0.4410428660394394\n",
      "iteration number 154, cost is 0.441008839571501\n",
      "iteration number 155, cost is 0.4409747969868005\n",
      "iteration number 156, cost is 0.4409407371506837\n",
      "iteration number 157, cost is 0.4409066590144086\n",
      "iteration number 158, cost is 0.44087256161021576\n",
      "iteration number 159, cost is 0.44083844404673533\n",
      "iteration number 160, cost is 0.44080430550471567\n",
      "iteration number 161, cost is 0.44077014523303276\n",
      "iteration number 162, cost is 0.44073596254498887\n",
      "iteration number 163, cost is 0.4407017568148559\n",
      "iteration number 164, cost is 0.44066752747464866\n",
      "iteration number 165, cost is 0.44063327401113445\n",
      "iteration number 166, cost is 0.4405989959630248\n",
      "iteration number 167, cost is 0.4405646929183739\n",
      "iteration number 168, cost is 0.44053036451213873\n",
      "iteration number 169, cost is 0.4404960104239076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number 170, cost is 0.44046163037578406\n",
      "iteration number 171, cost is 0.4404272241303962\n",
      "iteration number 172, cost is 0.4403927914890542\n",
      "iteration number 173, cost is 0.4403583322900141\n",
      "iteration number 174, cost is 0.4403238464068585\n",
      "iteration number 175, cost is 0.4402893337469821\n",
      "iteration number 176, cost is 0.4402547942501667\n",
      "iteration number 177, cost is 0.44022022788725557\n",
      "iteration number 178, cost is 0.44018563465890004\n",
      "iteration number 179, cost is 0.4401510145943819\n",
      "iteration number 180, cost is 0.44011636775051755\n",
      "iteration number 181, cost is 0.4400816942106138\n",
      "iteration number 182, cost is 0.4400469940834921\n",
      "iteration number 183, cost is 0.4400122675025586\n",
      "iteration number 184, cost is 0.4399775146249441\n",
      "iteration number 185, cost is 0.43994273563066727\n",
      "iteration number 186, cost is 0.43990793072185375\n",
      "iteration number 187, cost is 0.439873100122003\n",
      "iteration number 188, cost is 0.439838244075272\n",
      "iteration number 189, cost is 0.43980336284581023\n",
      "iteration number 190, cost is 0.43976845671711784\n",
      "iteration number 191, cost is 0.43973352599142684\n",
      "iteration number 192, cost is 0.4396985709891248\n",
      "iteration number 193, cost is 0.43966359204817834\n",
      "iteration number 194, cost is 0.43962858952360634\n",
      "iteration number 195, cost is 0.43959356378694575\n",
      "iteration number 196, cost is 0.4395585152257496\n",
      "iteration number 197, cost is 0.43952344424310447\n",
      "iteration number 198, cost is 0.43948835125714925\n",
      "iteration number 199, cost is 0.4394532367006212\n",
      "iteration number 200, cost is 0.43941810102039836\n",
      "iteration number 201, cost is 0.4393829446770732\n",
      "iteration number 202, cost is 0.43934776814451326\n",
      "iteration number 203, cost is 0.4393125719094475\n",
      "iteration number 204, cost is 0.4392773564710491\n",
      "iteration number 205, cost is 0.4392421223405341\n",
      "iteration number 206, cost is 0.43920687004075726\n",
      "iteration number 207, cost is 0.4391716001058176\n",
      "iteration number 208, cost is 0.43913631308066886\n",
      "iteration number 209, cost is 0.43910100952073305\n",
      "iteration number 210, cost is 0.4390656899915146\n",
      "iteration number 211, cost is 0.4390303550682215\n",
      "iteration number 212, cost is 0.43899500533538643\n",
      "iteration number 213, cost is 0.43895964138648785\n",
      "iteration number 214, cost is 0.4389242638235802\n",
      "iteration number 215, cost is 0.4388888732569166\n",
      "iteration number 216, cost is 0.4388534703045753\n",
      "iteration number 217, cost is 0.4388180555920941\n",
      "iteration number 218, cost is 0.43878262975209315\n",
      "iteration number 219, cost is 0.4387471934239071\n",
      "iteration number 220, cost is 0.43871174725321516\n",
      "iteration number 221, cost is 0.43867629189167207\n",
      "iteration number 222, cost is 0.43864082799653725\n",
      "iteration number 223, cost is 0.4386053562303106\n",
      "iteration number 224, cost is 0.4385698772603536\n",
      "iteration number 225, cost is 0.43853439175853126\n",
      "iteration number 226, cost is 0.4384989004008374\n",
      "iteration number 227, cost is 0.43846340386702926\n",
      "iteration number 228, cost is 0.43842790284026284\n",
      "iteration number 229, cost is 0.4383923980067172\n",
      "iteration number 230, cost is 0.438356890055241\n",
      "iteration number 231, cost is 0.438321379676974\n",
      "iteration number 232, cost is 0.4382858675649938\n",
      "iteration number 233, cost is 0.4382503544139454\n",
      "iteration number 234, cost is 0.43821484091968277\n",
      "iteration number 235, cost is 0.43817932777890856\n",
      "iteration number 236, cost is 0.4381438156888145\n",
      "iteration number 237, cost is 0.43810830534672296\n",
      "iteration number 238, cost is 0.438072797449738\n",
      "iteration number 239, cost is 0.43803729269438757\n",
      "iteration number 240, cost is 0.4380017917762756\n",
      "iteration number 241, cost is 0.4379662953897385\n",
      "iteration number 242, cost is 0.4379308042274965\n",
      "iteration number 243, cost is 0.43789531898031664\n",
      "iteration number 244, cost is 0.4378598403366771\n",
      "iteration number 245, cost is 0.4378243689824291\n",
      "iteration number 246, cost is 0.4377889056004745\n",
      "iteration number 247, cost is 0.43775345087043943\n",
      "iteration number 248, cost is 0.4377180054683501\n",
      "iteration number 249, cost is 0.43768257006632566\n",
      "iteration number 250, cost is 0.43764714533225996\n",
      "iteration number 251, cost is 0.43761173192952335\n",
      "iteration number 252, cost is 0.43757633051666134\n",
      "iteration number 253, cost is 0.4375409417470988\n",
      "iteration number 254, cost is 0.43750556626885784\n",
      "iteration number 255, cost is 0.43747020472427317\n",
      "iteration number 256, cost is 0.4374348577497166\n",
      "iteration number 257, cost is 0.43739952597533355\n",
      "iteration number 258, cost is 0.43736421002477816\n",
      "iteration number 259, cost is 0.437328910514961\n",
      "iteration number 260, cost is 0.43729362805580113\n",
      "iteration number 261, cost is 0.4372583632499883\n",
      "iteration number 262, cost is 0.4372231166927492\n",
      "iteration number 263, cost is 0.4371878889716283\n",
      "iteration number 264, cost is 0.4371526806662637\n",
      "iteration number 265, cost is 0.43711749234818686\n",
      "iteration number 266, cost is 0.43708232458061724\n",
      "iteration number 267, cost is 0.437047177918275\n",
      "iteration number 268, cost is 0.43701205290719164\n",
      "iteration number 269, cost is 0.43697695008454435\n",
      "iteration number 270, cost is 0.43694186997847934\n",
      "iteration number 271, cost is 0.4369068131079622\n",
      "iteration number 272, cost is 0.43687177998262333\n",
      "iteration number 273, cost is 0.4368367711026216\n",
      "iteration number 274, cost is 0.43680178695850835\n",
      "iteration number 275, cost is 0.4367668280311104\n",
      "iteration number 276, cost is 0.43673189479140845\n",
      "iteration number 277, cost is 0.4366969877004389\n",
      "iteration number 278, cost is 0.4366621072091908\n",
      "iteration number 279, cost is 0.43662725375851996\n",
      "iteration number 280, cost is 0.4365924277790758\n",
      "iteration number 281, cost is 0.43655762969121487\n",
      "iteration number 282, cost is 0.4365228599049565\n",
      "iteration number 283, cost is 0.4364881188199168\n",
      "iteration number 284, cost is 0.436453406825265\n",
      "iteration number 285, cost is 0.43641872429969253\n",
      "iteration number 286, cost is 0.4363840716113763\n",
      "iteration number 287, cost is 0.436349449117958\n",
      "iteration number 288, cost is 0.43631485716653795\n",
      "iteration number 289, cost is 0.43628029609366215\n",
      "iteration number 290, cost is 0.4362457662253264\n",
      "iteration number 291, cost is 0.43621126787698855\n",
      "iteration number 292, cost is 0.43617680135358106\n",
      "iteration number 293, cost is 0.43614236694953995\n",
      "iteration number 294, cost is 0.43610796494883086\n",
      "iteration number 295, cost is 0.4360735956249896\n",
      "iteration number 296, cost is 0.43603925924116704\n",
      "iteration number 297, cost is 0.43600495605018114\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [18], line 80\u001b[0m, in \u001b[0;36mmodel.train\u001b[1;34m(s, X, Y, lr, l)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m s\u001b[38;5;241m.\u001b[39mstop\u001b[38;5;241m!=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m     k\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 80\u001b[0m     \u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_one_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcost\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43ml\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration number \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, cost is \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k,s\u001b[38;5;241m.\u001b[39mcost))\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe stopped cause cost function didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt change enough in last iteration\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn [18], line 48\u001b[0m, in \u001b[0;36mmodel.make_one_iteration\u001b[1;34m(s, X, Y, previous_cost, lr, l)\u001b[0m\n\u001b[0;32m     45\u001b[0m         a\u001b[38;5;241m.\u001b[39mappend(sig(z[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m#backpropagation\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m E_total\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mY[t]\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mlog(a[\u001b[38;5;28mlen\u001b[39m(arch)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m-\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mY[t])\u001b[38;5;241m*\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43march\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m sum_er\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39mE_total\n\u001b[0;32m     50\u001b[0m deltas\u001b[38;5;241m=\u001b[39m[]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nn.train(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "e9461739",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=pd.read_csv(\"test.csv\")[[\"Pclass\",\"Sex\",\"Age\",\"Fare\",\"SibSp\",\"Parch\"]]\n",
    "test_data=test_data.fillna(value={\"Age\":np.mean(data[\"Age\"]),\"Fare\":np.mean(data[\"Fare\"])})\n",
    "X_test=test_data[[\"Pclass\",\"Sex\",\"Age\",\"Fare\",\"SibSp\",\"Parch\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "5af898fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.loc[X_test.Sex==\"male\",\"Sex\"]=0\n",
    "X_test.loc[X_test.Sex==\"female\",\"Sex\"]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "fdfda28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "sex_values=list(X_test[\"Sex\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "91605906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(sex_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "b1caf788",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=s.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "6e0fc0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PearsonRResult(statistic=0.8030591828580931, pvalue=1.4411987961468749e-95)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting scatter plot for X_test[Sex]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(nn.predict(X_test),sex_values)\n",
    "plt.show\n",
    "#Count Pearson correlation \n",
    "import scipy.stats as ss\n",
    "print(ss.pearsonr(sex_values,list(map(round,nn.predict(X_test)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "12d2abdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=nn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea99624e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "6af15eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test=np.array(pd.read_csv(\"gender_submission.csv\")[[\"Survived\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "0f3a30f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test=Y_test.reshape(len(Y_test),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "78e374c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [345], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sub\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassengerId\u001b[39m\u001b[38;5;124m\"\u001b[39m:pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassengerId\u001b[39m\u001b[38;5;124m\"\u001b[39m],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSurvived\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mround\u001b[39m,\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m))})\n",
      "Cell \u001b[1;32mIn [337], line 93\u001b[0m, in \u001b[0;36mmodel.predict\u001b[1;34m(s, X)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(s\u001b[38;5;241m.\u001b[39march)):\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m         a\u001b[38;5;241m.\u001b[39mappend(\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,s\u001b[38;5;241m.\u001b[39march[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m         z\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmatmul(a[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],weights[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mtranspose()))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:3804\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3804\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3806\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "sub=pd.DataFrame({\"PassengerId\":pd.read_csv(\"test.csv\")[\"PassengerId\"],\"Survived\":list(map(round,nn.predict(X_test)))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "d26bb09b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "3a00cbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"sub.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adff0777",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_test[891:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798ef410",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(sub[\"Survived\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d6f2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "4cb85a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.8821548821548821, precision is 0.8128654970760234,recall is 0.9253187613843351\n"
     ]
    }
   ],
   "source": [
    "a=0\n",
    "p=0\n",
    "r=0\n",
    "k_1=0\n",
    "k_0=0\n",
    "for i in zip(list(map(round,nn.predict(X_train))),Y_train):\n",
    "    if i[1]==1:\n",
    "        k_1+=1\n",
    "    if i[1]==0:\n",
    "        k_0+=1\n",
    "    if i[0]==i[1]:\n",
    "        a+=1\n",
    "    if i[0]==i[1]==1:\n",
    "        p+=1\n",
    "    if i[0]==i[1]==0:\n",
    "        r+=1\n",
    "metrics=[a/len(Y_train),p/k_1,r/k_0]\n",
    "accuracy,precision,recall=metrics\n",
    "print(\"accuracy is {0}, precision is {1},recall is {2}\".format(accuracy,precision,recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96708f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,weights,arch): \n",
    "    print(arch)\n",
    "    predictions=[]\n",
    "    for t in range(len(X)):\n",
    "    #forward propagation\n",
    "        a=[]\n",
    "        z=[]\n",
    "        for i in range(len(arch)):\n",
    "            if i==0:\n",
    "                a.append(X[t].reshape(1,arch[0]))\n",
    "            else:\n",
    "                z.append(np.matmul(a[i-1],weights[i-1].transpose()))\n",
    "                a.append(sig(z[i-1]))\n",
    "        predictions.append(a[len(arch)-1])\n",
    "    return predictions       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8305ab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=np.array(predict(X,weights,arch))\n",
    "pred=pred.reshape(len(pred),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dff0076",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392be003",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rounded=list(map(lambda x:1 if x>=0.5 else 0,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f5557c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_train.reshape(714,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5608c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2576386",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0\n",
    "for i in zip(pred_rounded,Y_train):\n",
    "    if i[0]==i[1]:\n",
    "        k+=1\n",
    "print(\"accuracy=\",k/len(Y_train))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
